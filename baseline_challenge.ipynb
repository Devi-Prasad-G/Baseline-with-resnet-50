{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6qGPDxzAE0jHxD93ZSx/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devi-Prasad-G/Baseline-with-resnet-50-Limited-Data-problem-/blob/main/baseline_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fqU6qHH5Hhq"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a model(resnet-50)"
      ],
      "metadata": {
        "id": "8GLC_QSr5X3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.ResNet50(weights=None, include_top=True, input_tensor=model_input,classes = 1000) # without using imagenet weights"
      ],
      "metadata": {
        "id": "-2U_RHFl5QIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we add the preprocess layers to the model instead of the data loader\n",
        "input_shape = (256,256,3)\n",
        "input_shape_model = (224,224,3)\n",
        "s=389\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
        "x = tf.keras.layers.Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229**2, 0.224**2, 0.225**2])(x) #normalizing with mean and variance of train data\n",
        "x = tf.keras.layers.RandomCrop(height=224,width=224,seed=s)(x)\n",
        "outputs = model(x)\n",
        "new_model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "lffochGY5QFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading train data"
      ],
      "metadata": {
        "id": "V3qLdZbT6I_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/train.zip -d /content # to unzip the training file in drive"
      ],
      "metadata": {
        "id": "akvk9-CI5QCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                                  fill_mode='nearest',\n",
        "                                   validation_split=0.2)\n",
        "training_set = train_datagen.flow_from_directory('./train',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='training')\n",
        "\n",
        "validation_set = train_datagen.flow_from_directory('./train',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='validation')"
      ],
      "metadata": {
        "id": "TuyEHFKq5P__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model parameters and savepoints"
      ],
      "metadata": {
        "id": "iMoWBYMR6e-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_rate = 0.1 #original lr rate\n",
        "wd = 0.0001\n",
        "def scheduler(epoch, lr):\n",
        "    return l_rate * (0.1 ** (epoch // 30))\n",
        "\n",
        "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/adv1/model_best.h5\",\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#loss = tf.keras.losses.sparse_categorical_crossentropy()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "#add weight decay to SGW\n",
        "optim = tfa.optimizers.SGDW(learning_rate=l_rate, weight_decay=wd, momentum=0.9, nesterov = False, name = 'SGDW')"
      ],
      "metadata": {
        "id": "pVdUHpsn5P9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "tPOFk5gU6zE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.compile(loss=loss,\n",
        "              optimizer=optim,\n",
        "              metrics=['accuracy'])\n",
        "new_model.fit(training_set, validation_data = validation_set, epochs=90,steps_per_epoch=training_set.samples//32,validation_steps=validation_set.samples //32,verbose=1,callbacks = [callback_lr,checkpoint])"
      ],
      "metadata": {
        "id": "JgaxJqBr5P6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.save(\"/content/drive/MyDrive/adv1_final\")"
      ],
      "metadata": {
        "id": "2SD8Qk1h5P3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}